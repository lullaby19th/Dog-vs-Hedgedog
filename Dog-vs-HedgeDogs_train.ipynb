{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ Image Files resize (32x32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 # 이미지나 영상을 처리하는 모듈\n",
    "\n",
    "path = [\"E:\\data10\\classification\\dogs\"] \n",
    "# E:\\data10\\classification\\dogs \n",
    "# E:\\data10\\classification\\hedgedogs\n",
    "\n",
    "j = 0\n",
    "for k in path:\n",
    "    file_list = os.listdir(k)\n",
    "    file_name = []\n",
    "    for i in file_list:\n",
    "        if  i not in ['resized_2.jpg','resized_3.jpg','resized_4.jpg']:\n",
    "            file_name.append(int( i[:-4] ))\n",
    "    file_name.sort()\n",
    "    file_list = [k + '\\\\' + str(i) + '.jpg' for i in file_name]\n",
    "    \n",
    "    for i in file_list:\n",
    "        img = cv2.imread(i)\n",
    "        width, height = img.shape[:2]\n",
    "        resize = cv2.resize(img, (int(32), int(32)), interpolation=cv2.INTER_CUBIC) # 현재 32 x 32로 resize\n",
    "        cv2.imwrite(\"d:\\\\resize\\\\\" + str(j + 1) + '.jpg', resize)\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ Create Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'E:\\data10\\classification\\\\train_label.csv'\n",
    "file = open( path, 'w')\n",
    "for  i  in  range(1, 1630):\n",
    "    file.write( str(1) + '\\n' )\n",
    "for  i  in  range(1, 978):\n",
    "    file.write( str(0) + '\\n') \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'E:\\data10\\classification\\\\test_label.csv'\n",
    "file = open( path, 'w')\n",
    "for  i  in  range(1, 182):\n",
    "    file.write( str(1) + '\\n' )\n",
    "for  i  in  range(1, 109):\n",
    "     file.write( str(0) + '\\n') \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ Create loader3.py \n",
    "\n",
    " ■ image_load  \n",
    " ■ next_batch  \n",
    " ■ shuffle_batch  \n",
    " ■ label_load  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  csv\n",
    "import  os\n",
    "import  re\n",
    "import  cv2\n",
    "import  random\n",
    "import  numpy  as  np\n",
    "\n",
    "def  image_load(path):\n",
    "    file_list = os.listdir(path)\n",
    "    file_name = []\n",
    "    for  i  in  file_list:\n",
    "        a = int(  re.sub('[^0-9]', '', i )  ) # 숫자가 아닌것은 '' 로 처리 \n",
    "        file_name.append(a) \n",
    "    file_name.sort()\n",
    "\n",
    "    file_res = [] \n",
    "    for  j  in   file_name:\n",
    "        file_res.append('%s\\\\%d.jpg' %(path,j)  )\n",
    "\n",
    "    image = []\n",
    "    for  k  in  file_res:\n",
    "        img = cv2.imread(k)\n",
    "        image.append(img)\n",
    "\n",
    "    return  np.array(image)\n",
    "\n",
    "def  label_load( path ):\n",
    "    file = open(path)\n",
    "    labeldata = csv.reader(file)\n",
    "    labellist = []\n",
    "    for  i   in  labeldata:\n",
    "        labellist.append(i)\n",
    "\n",
    "    label = np.array(labellist)\n",
    "    label = label.astype(int)  # 숫자로 변환 \n",
    "    label = np.eye(2)[label]\n",
    "    label = label.reshape(-1,2) \n",
    "    return  label\n",
    "\n",
    "\n",
    "def  shuffle_batch( data_list, label ):\n",
    "    x = np.arange( len( data_list) )\n",
    "    random.shuffle(x)\n",
    "    data_list2 = data_list[x]\n",
    "    label2 = label[x]\n",
    "    return   data_list2, label2 \n",
    "\n",
    "\n",
    "def  next_batch( data1, data2, init,  fina ):\n",
    "    return  data1[ init : fina ],  data2[init : fina] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2606, 32, 32, 3)\n",
      "(2606, 2)\n",
      "(289, 32, 32, 3)\n",
      "(289, 2)\n"
     ]
    }
   ],
   "source": [
    "import loader3\n",
    "\n",
    "train_image='E:\\\\data10\\\\classification\\\\train_resize\\\\'\n",
    "train_label= 'E:\\\\data10\\\\classification\\\\train_label.csv'\n",
    "test_image='E:\\\\data10\\\\classification\\\\test_resize\\\\'\n",
    "test_label='E:\\\\data10\\\\classification\\\\test_label.csv'\n",
    "\n",
    "print(loader3.image_load(train_image).shape)\n",
    "print(loader3.label_load(train_label).shape)\n",
    "print(loader3.image_load(test_image).shape)\n",
    "print(loader3.label_load(test_label).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ Train start ( vgg9.ver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2606, 32, 32, 3)\n",
      "(2606, 2)\n",
      "(289, 32, 32, 3)\n",
      "(289, 2)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 32, 32, 128)       3584      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              8389632   \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 2050      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 14,033,026\n",
      "Trainable params: 14,025,346\n",
      "Non-trainable params: 7,680\n",
      "_________________________________________________________________\n",
      "Train on 2606 samples, validate on 289 samples\n",
      "Epoch 1/50\n",
      "2606/2606 [==============================] - 5s 2ms/step - loss: 0.9996 - accuracy: 0.5706 - val_loss: 1.1146 - val_accuracy: 0.4325\n",
      "Epoch 2/50\n",
      "2606/2606 [==============================] - 3s 1ms/step - loss: 0.8509 - accuracy: 0.5906 - val_loss: 0.7129 - val_accuracy: 0.4740\n",
      "Epoch 3/50\n",
      "2606/2606 [==============================] - 3s 1ms/step - loss: 0.7485 - accuracy: 0.6404 - val_loss: 0.8684 - val_accuracy: 0.4118\n",
      "Epoch 4/50\n",
      "2606/2606 [==============================] - 3s 1ms/step - loss: 0.6986 - accuracy: 0.6781 - val_loss: 0.6384 - val_accuracy: 0.6401\n",
      "Epoch 5/50\n",
      "2606/2606 [==============================] - 3s 1ms/step - loss: 0.6809 - accuracy: 0.6769 - val_loss: 0.8631 - val_accuracy: 0.4291\n",
      "Epoch 6/50\n",
      "2606/2606 [==============================] - 3s 1ms/step - loss: 0.6657 - accuracy: 0.6892 - val_loss: 0.5895 - val_accuracy: 0.6609\n",
      "Epoch 7/50\n",
      "2606/2606 [==============================] - 3s 1ms/step - loss: 0.7231 - accuracy: 0.6243 - val_loss: 0.6118 - val_accuracy: 0.6367\n",
      "Epoch 8/50\n",
      "2606/2606 [==============================] - 3s 1ms/step - loss: 0.6436 - accuracy: 0.6823 - val_loss: 1.0054 - val_accuracy: 0.3772\n",
      "Epoch 9/50\n",
      "2606/2606 [==============================] - 3s 1ms/step - loss: 0.5649 - accuracy: 0.7460 - val_loss: 1.0985 - val_accuracy: 0.4671\n",
      "Epoch 10/50\n",
      "2606/2606 [==============================] - 3s 1ms/step - loss: 0.7176 - accuracy: 0.5902 - val_loss: 0.6706 - val_accuracy: 0.5363\n",
      "Epoch 11/50\n",
      "2606/2606 [==============================] - 3s 1ms/step - loss: 0.7044 - accuracy: 0.6021 - val_loss: 0.6482 - val_accuracy: 0.6263\n",
      "Epoch 12/50\n",
      "2606/2606 [==============================] - 3s 1ms/step - loss: 0.6393 - accuracy: 0.6416 - val_loss: 0.8616 - val_accuracy: 0.3737\n",
      "Epoch 13/50\n",
      "2606/2606 [==============================] - 3s 1ms/step - loss: 0.7183 - accuracy: 0.5932 - val_loss: 0.6855 - val_accuracy: 0.5156\n",
      "Epoch 14/50\n",
      "2606/2606 [==============================] - 3s 1ms/step - loss: 0.6776 - accuracy: 0.6243 - val_loss: 0.7281 - val_accuracy: 0.3979\n",
      "Epoch 15/50\n",
      "2606/2606 [==============================] - 3s 1ms/step - loss: 0.6862 - accuracy: 0.6120 - val_loss: 0.7877 - val_accuracy: 0.3841\n",
      "Epoch 16/50\n",
      "2606/2606 [==============================] - 3s 1ms/step - loss: 0.6741 - accuracy: 0.6224 - val_loss: 0.6711 - val_accuracy: 0.5882\n",
      "Epoch 17/50\n",
      "2606/2606 [==============================] - 3s 1ms/step - loss: 0.6424 - accuracy: 0.6385 - val_loss: 0.8701 - val_accuracy: 0.3979\n",
      "Epoch 18/50\n",
      "2606/2606 [==============================] - 3s 1ms/step - loss: 0.6123 - accuracy: 0.6685 - val_loss: 0.6598 - val_accuracy: 0.6055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50\n",
      "2606/2606 [==============================] - 3s 1ms/step - loss: 0.5775 - accuracy: 0.7045 - val_loss: 0.6097 - val_accuracy: 0.6851\n",
      "Epoch 20/50\n",
      "2606/2606 [==============================] - 3s 1ms/step - loss: 0.5532 - accuracy: 0.7360 - val_loss: 0.7859 - val_accuracy: 0.4083\n",
      "Epoch 21/50\n",
      "2606/2606 [==============================] - 3s 1ms/step - loss: 0.5209 - accuracy: 0.7594 - val_loss: 0.5893 - val_accuracy: 0.6401\n",
      "Epoch 22/50\n",
      "2606/2606 [==============================] - 3s 1ms/step - loss: 0.4935 - accuracy: 0.7675 - val_loss: 0.6595 - val_accuracy: 0.5294\n",
      "Epoch 23/50\n",
      "2606/2606 [==============================] - 3s 1ms/step - loss: 0.4702 - accuracy: 0.7847 - val_loss: 0.6679 - val_accuracy: 0.5329\n",
      "Epoch 24/50\n",
      "2606/2606 [==============================] - 3s 1ms/step - loss: 0.4638 - accuracy: 0.7817 - val_loss: 1.1955 - val_accuracy: 0.3979\n",
      "Epoch 25/50\n",
      "2606/2606 [==============================] - 3s 1ms/step - loss: 0.5525 - accuracy: 0.7233 - val_loss: 0.8104 - val_accuracy: 0.4879\n",
      "Epoch 26/50\n",
      "2606/2606 [==============================] - 3s 1ms/step - loss: 0.5007 - accuracy: 0.7698 - val_loss: 0.4891 - val_accuracy: 0.7682\n",
      "Epoch 27/50\n",
      "2606/2606 [==============================] - 3s 1ms/step - loss: 0.6052 - accuracy: 0.6922 - val_loss: 0.8581 - val_accuracy: 0.4291\n",
      "Epoch 28/50\n",
      "2606/2606 [==============================] - 3s 1ms/step - loss: 0.5062 - accuracy: 0.7617 - val_loss: 0.5804 - val_accuracy: 0.7197\n",
      "Epoch 29/50\n",
      "2606/2606 [==============================] - 3s 1ms/step - loss: 0.4600 - accuracy: 0.7889 - val_loss: 0.5719 - val_accuracy: 0.6955\n",
      "Epoch 30/50\n",
      "2606/2606 [==============================] - 3s 1ms/step - loss: 0.4713 - accuracy: 0.7843 - val_loss: 0.7721 - val_accuracy: 0.5017\n",
      "Epoch 31/50\n",
      "2606/2606 [==============================] - 3s 1ms/step - loss: 0.4519 - accuracy: 0.7982 - val_loss: 0.5630 - val_accuracy: 0.7093\n",
      "Epoch 32/50\n",
      "2606/2606 [==============================] - 3s 1ms/step - loss: 0.4448 - accuracy: 0.7982 - val_loss: 0.4700 - val_accuracy: 0.7958\n",
      "Epoch 33/50\n",
      "2606/2606 [==============================] - 3s 1ms/step - loss: 0.4340 - accuracy: 0.7966 - val_loss: 0.4468 - val_accuracy: 0.7993\n",
      "Epoch 34/50\n",
      "2606/2606 [==============================] - 3s 1ms/step - loss: 0.4141 - accuracy: 0.8158 - val_loss: 0.4679 - val_accuracy: 0.8062\n",
      "Epoch 35/50\n",
      "2606/2606 [==============================] - 3s 1ms/step - loss: 0.4106 - accuracy: 0.8150 - val_loss: 0.4889 - val_accuracy: 0.7889\n",
      "Epoch 36/50\n",
      "2606/2606 [==============================] - 3s 1ms/step - loss: 0.4674 - accuracy: 0.7843 - val_loss: 0.4439 - val_accuracy: 0.8201\n",
      "Epoch 37/50\n",
      "2606/2606 [==============================] - 3s 1ms/step - loss: 0.4702 - accuracy: 0.7721 - val_loss: 0.5614 - val_accuracy: 0.6782\n",
      "Epoch 38/50\n",
      "2606/2606 [==============================] - 3s 1ms/step - loss: 0.4087 - accuracy: 0.8097 - val_loss: 0.4187 - val_accuracy: 0.8201\n",
      "Epoch 39/50\n",
      "2606/2606 [==============================] - 3s 1ms/step - loss: 0.4466 - accuracy: 0.7897 - val_loss: 0.4415 - val_accuracy: 0.8270\n",
      "Epoch 40/50\n",
      "2606/2606 [==============================] - 3s 1ms/step - loss: 0.4617 - accuracy: 0.7866 - val_loss: 0.4306 - val_accuracy: 0.8235\n",
      "Epoch 41/50\n",
      "2606/2606 [==============================] - 3s 1ms/step - loss: 0.4052 - accuracy: 0.8124 - val_loss: 0.4917 - val_accuracy: 0.7682\n",
      "Epoch 42/50\n",
      "2606/2606 [==============================] - 3s 1ms/step - loss: 0.3997 - accuracy: 0.8200 - val_loss: 0.4114 - val_accuracy: 0.8754\n",
      "Epoch 43/50\n",
      "2606/2606 [==============================] - 3s 1ms/step - loss: 0.3588 - accuracy: 0.8434 - val_loss: 0.4162 - val_accuracy: 0.7993\n",
      "Epoch 44/50\n",
      "2606/2606 [==============================] - 3s 1ms/step - loss: 0.3595 - accuracy: 0.8423 - val_loss: 0.4200 - val_accuracy: 0.8581\n",
      "Epoch 45/50\n",
      "2606/2606 [==============================] - 3s 1ms/step - loss: 0.3543 - accuracy: 0.8408 - val_loss: 0.3843 - val_accuracy: 0.8304\n",
      "Epoch 46/50\n",
      "2606/2606 [==============================] - 3s 1ms/step - loss: 0.3483 - accuracy: 0.8511 - val_loss: 0.4631 - val_accuracy: 0.7820\n",
      "Epoch 47/50\n",
      "2606/2606 [==============================] - 3s 1ms/step - loss: 0.3442 - accuracy: 0.8461 - val_loss: 0.3856 - val_accuracy: 0.8374\n",
      "Epoch 48/50\n",
      "2606/2606 [==============================] - 3s 1ms/step - loss: 0.3460 - accuracy: 0.8469 - val_loss: 0.3780 - val_accuracy: 0.8547\n",
      "Epoch 49/50\n",
      "2606/2606 [==============================] - 3s 1ms/step - loss: 0.3342 - accuracy: 0.8569 - val_loss: 0.4748 - val_accuracy: 0.7509\n",
      "Epoch 50/50\n",
      "2606/2606 [==============================] - 3s 1ms/step - loss: 0.3229 - accuracy: 0.8561 - val_loss: 0.4203 - val_accuracy: 0.8097\n",
      "289/289 [==============================] - 0s 311us/step\n",
      "['고슴도치']\n",
      "['고슴도치']\n"
     ]
    }
   ],
   "source": [
    "import os, cv2, random\n",
    "\n",
    "# 필요한 라이브러리 import 하는 코드 \n",
    "import numpy as np\n",
    "\n",
    "from keras.layers import Input, Flatten, Dense, Conv2D, BatchNormalization, LeakyReLU, Dropout, Activation, MaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K   # 백엔드가  텐서 플로우로 되어있어서 \n",
    "                                     # 텐서 플로우 명령어 필요할 때 tf 대신에 \n",
    "                                     # k 를 쓰겠다라는 의미 \n",
    "\n",
    "import loader3\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "train_image='E:\\\\data10\\\\classification\\\\train_resize\\\\'\n",
    "train_label= 'E:\\\\data10\\\\classification\\\\train_label.csv'\n",
    "test_image='E:\\\\data10\\\\classification\\\\test_resize\\\\'\n",
    "test_label='E:\\\\data10\\\\classification\\\\test_label.csv'\n",
    "\n",
    "print(loader3.image_load(train_image).shape)\n",
    "print(loader3.label_load(train_label).shape)\n",
    "print(loader3.image_load(test_image).shape)\n",
    "print(loader3.label_load(test_label).shape)\n",
    "\n",
    "x_train = loader3.image_load(train_image)\n",
    "y_train = loader3.label_load(train_label)\n",
    "x_test = loader3.image_load(test_image)\n",
    "y_test = loader3.label_load(test_label)\n",
    "\n",
    "\n",
    "# 모델 만들기 \n",
    "input_layer = Input((32,32,3))\n",
    "\n",
    "x = Conv2D(filters = 128, kernel_size = 3, strides = 1, padding = 'same')(input_layer)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(rate = 0.5)(x)\n",
    "\n",
    "x = Conv2D(filters = 128, kernel_size = 3, strides = 1, padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(rate = 0.5)(x)\n",
    "x = MaxPooling2D(pool_size=2,strides=2)(x)\n",
    "\n",
    "\n",
    "x = Conv2D(filters = 256, kernel_size = 3, strides = 1, padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(rate = 0.5)(x)\n",
    "\n",
    "x = Conv2D(filters = 256, kernel_size = 3, strides = 1, padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(rate = 0.5)(x)\n",
    "\n",
    "x = MaxPooling2D(pool_size=2,strides=2)(x)\n",
    "\n",
    "\n",
    "x = Conv2D(filters = 512, kernel_size = 3, strides = 1, padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(rate = 0.5)(x)\n",
    "\n",
    "x = Conv2D(filters = 512, kernel_size = 3, strides = 1, padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(rate = 0.5)(x)\n",
    "\n",
    "x = MaxPooling2D(pool_size=2,strides=2)(x)\n",
    "\n",
    "\n",
    "\n",
    "# 완전 연결 계층 \n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dense(1024)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(rate = 0.5)(x)\n",
    "\n",
    "x = Dense(1024)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(rate = 0.5)(x)\n",
    "\n",
    "x = Dense(NUM_CLASSES)(x)\n",
    "output_layer = Activation('softmax')(x)\n",
    "\n",
    "model = Model(input_layer, output_layer)\n",
    "\n",
    "# convolution 층 6개, 완전 연결계층 2개 출력층 1개인 9층 신경망 \n",
    "\n",
    "model.summary()\n",
    "\n",
    "# 모델 훈련\n",
    "\n",
    "model_exists = False\n",
    "\n",
    "\n",
    "if model_exists:\n",
    "    \n",
    "    \n",
    "    model.load_weights('E:\\data10\\classification\\\\resultvgg9.h5')\n",
    "    \n",
    "    CLASSES = np.array(['개', '고슴도치' ]) \n",
    "    preds = model.predict( x_test[1:2] )   \n",
    "    preds_value = CLASSES[ np.argmax( preds, axis= -1 ) ] \n",
    "    actual_value = CLASSES[ np.argmax( y_test [1:2], axis = -1) ] \n",
    "    print ( preds_value)\n",
    "    print ( actual_value)\n",
    "    \n",
    "else:\n",
    "        \n",
    "    opt = Adam(lr=0.0005)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(x_train\n",
    "              , y_train\n",
    "              , batch_size=28\n",
    "              , epochs=50\n",
    "              , shuffle=True\n",
    "               , validation_data=(x_test,y_test) )\n",
    "    \n",
    "    \n",
    "    model.save_weights('E:\\data10\\classification\\\\resultvgg9.h5')\n",
    "    \n",
    "    model.evaluate(x_test, y_test, batch_size=28)\n",
    "    \n",
    "    CLASSES = np.array(['개', '고슴도치' ]) \n",
    "    preds = model.predict( x_test[1:2] )   \n",
    "    preds_value = CLASSES[ np.argmax( preds, axis= -1 ) ] \n",
    "    actual_value = CLASSES[ np.argmax( y_test[1:2], axis = -1) ] \n",
    "    print ( preds_value)\n",
    "    print ( actual_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf2.0-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
