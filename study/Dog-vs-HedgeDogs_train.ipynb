{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ Image Files resize (32x32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 # 이미지나 영상을 처리하는 모듈\n",
    "\n",
    "path = [\"E:\\data10\\classification\\dogs\"] \n",
    "# E:\\data10\\classification\\dogs \n",
    "# E:\\data10\\classification\\hedgedogs\n",
    "\n",
    "j = 0\n",
    "for k in path:\n",
    "    file_list = os.listdir(k)\n",
    "    file_name = []\n",
    "    for i in file_list:\n",
    "        if  i not in ['resized_2.jpg','resized_3.jpg','resized_4.jpg']:\n",
    "            file_name.append(int( i[:-4] ))\n",
    "    file_name.sort()\n",
    "    file_list = [k + '\\\\' + str(i) + '.jpg' for i in file_name]\n",
    "    \n",
    "    for i in file_list:\n",
    "        img = cv2.imread(i)\n",
    "        width, height = img.shape[:2]\n",
    "        resize = cv2.resize(img, (int(32), int(32)), interpolation=cv2.INTER_CUBIC) # 현재 32 x 32로 resize\n",
    "        cv2.imwrite(\"d:\\\\resize\\\\\" + str(j + 1) + '.jpg', resize)\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ Create Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'E:\\data10\\classification\\\\train_label.csv'\n",
    "file = open( path, 'w')\n",
    "for  i  in  range(1, 1630):\n",
    "    file.write( str(1) + '\\n' )\n",
    "for  i  in  range(1, 978):\n",
    "    file.write( str(0) + '\\n') \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'E:\\data10\\classification\\\\test_label.csv'\n",
    "file = open( path, 'w')\n",
    "for  i  in  range(1, 182):\n",
    "    file.write( str(1) + '\\n' )\n",
    "for  i  in  range(1, 109):\n",
    "     file.write( str(0) + '\\n') \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ Create loader3.py \n",
    "\n",
    " ■ image_load  \n",
    " ■ next_batch  \n",
    " ■ shuffle_batch  \n",
    " ■ label_load  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  csv\n",
    "import  os\n",
    "import  re\n",
    "import  cv2\n",
    "import  random\n",
    "import  numpy  as  np\n",
    "\n",
    "def  image_load(path):\n",
    "    file_list = os.listdir(path)\n",
    "    file_name = []\n",
    "    for  i  in  file_list:\n",
    "        a = int(  re.sub('[^0-9]', '', i )  ) # 숫자가 아닌것은 '' 로 처리 \n",
    "        file_name.append(a) \n",
    "    file_name.sort()\n",
    "\n",
    "    file_res = [] \n",
    "    for  j  in   file_name:\n",
    "        file_res.append('%s\\\\%d.jpg' %(path,j)  )\n",
    "\n",
    "    image = []\n",
    "    for  k  in  file_res:\n",
    "        img = cv2.imread(k)\n",
    "        image.append(img)\n",
    "\n",
    "    return  np.array(image)\n",
    "\n",
    "def  label_load( path ):\n",
    "    file = open(path)\n",
    "    labeldata = csv.reader(file)\n",
    "    labellist = []\n",
    "    for  i   in  labeldata:\n",
    "        labellist.append(i)\n",
    "\n",
    "    label = np.array(labellist)\n",
    "    label = label.astype(int)  # 숫자로 변환 \n",
    "    label = np.eye(2)[label]\n",
    "    label = label.reshape(-1,2) \n",
    "    return  label\n",
    "\n",
    "\n",
    "def  shuffle_batch( data_list, label ):\n",
    "    x = np.arange( len( data_list) )\n",
    "    random.shuffle(x)\n",
    "    data_list2 = data_list[x]\n",
    "    label2 = label[x]\n",
    "    return   data_list2, label2 \n",
    "\n",
    "\n",
    "def  next_batch( data1, data2, init,  fina ):\n",
    "    return  data1[ init : fina ],  data2[init : fina] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2606, 32, 32, 3)\n",
      "(2606, 2)\n",
      "(289, 32, 32, 3)\n",
      "(289, 2)\n"
     ]
    }
   ],
   "source": [
    "import loader3\n",
    "\n",
    "train_image='E:\\\\data10\\\\classification\\\\train_resize\\\\'\n",
    "train_label= 'E:\\\\data10\\\\classification\\\\train_label.csv'\n",
    "test_image='E:\\\\data10\\\\classification\\\\test_resize\\\\'\n",
    "test_label='E:\\\\data10\\\\classification\\\\test_label.csv'\n",
    "\n",
    "print(loader3.image_load(train_image).shape)\n",
    "print(loader3.label_load(train_label).shape)\n",
    "print(loader3.image_load(test_image).shape)\n",
    "print(loader3.label_load(test_label).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ Train start (vgg9.ver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2, random\n",
    "\n",
    "# 필요한 라이브러리 import 하는 코드 \n",
    "import numpy as np\n",
    "\n",
    "from keras.layers import Input, Flatten, Dense, Conv2D, BatchNormalization, LeakyReLU, Dropout, Activation, MaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K   # 백엔드가  텐서 플로우로 되어있어서 \n",
    "                                     # 텐서 플로우 명령어 필요할 때 tf 대신에 \n",
    "                                     # k 를 쓰겠다라는 의미 \n",
    "\n",
    "import loader3\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "train_image='E:\\\\data10\\\\classification\\\\train_resize\\\\'\n",
    "train_label= 'E:\\\\data10\\\\classification\\\\train_label.csv'\n",
    "test_image='E:\\\\data10\\\\classification\\\\test_resize\\\\'\n",
    "test_label='E:\\\\data10\\\\classification\\\\test_label.csv'\n",
    "\n",
    "print(loader3.image_load(train_image).shape)\n",
    "print(loader3.label_load(train_label).shape)\n",
    "print(loader3.image_load(test_image).shape)\n",
    "print(loader3.label_load(test_label).shape)\n",
    "\n",
    "x_train = loader3.image_load(train_image)\n",
    "y_train = loader3.label_load(train_label)\n",
    "x_test = loader3.image_load(test_image)\n",
    "y_test = loader3.label_load(test_label)\n",
    "\n",
    "\n",
    "# 모델 만들기 \n",
    "input_layer = Input((32,32,3))\n",
    "\n",
    "x = Conv2D(filters = 128, kernel_size = 3, strides = 1, padding = 'same')(input_layer)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(rate = 0.5)(x)\n",
    "\n",
    "x = Conv2D(filters = 128, kernel_size = 3, strides = 1, padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(rate = 0.5)(x)\n",
    "x = MaxPooling2D(pool_size=2,strides=2)(x)\n",
    "\n",
    "\n",
    "x = Conv2D(filters = 256, kernel_size = 3, strides = 1, padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(rate = 0.5)(x)\n",
    "\n",
    "x = Conv2D(filters = 256, kernel_size = 3, strides = 1, padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(rate = 0.5)(x)\n",
    "\n",
    "x = MaxPooling2D(pool_size=2,strides=2)(x)\n",
    "\n",
    "\n",
    "x = Conv2D(filters = 512, kernel_size = 3, strides = 1, padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(rate = 0.5)(x)\n",
    "\n",
    "x = Conv2D(filters = 512, kernel_size = 3, strides = 1, padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(rate = 0.5)(x)\n",
    "\n",
    "x = MaxPooling2D(pool_size=2,strides=2)(x)\n",
    "\n",
    "\n",
    "\n",
    "# 완전 연결 계층 \n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dense(1024)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(rate = 0.5)(x)\n",
    "\n",
    "x = Dense(1024)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(rate = 0.5)(x)\n",
    "\n",
    "x = Dense(NUM_CLASSES)(x)\n",
    "output_layer = Activation('softmax')(x)\n",
    "\n",
    "model = Model(input_layer, output_layer)\n",
    "\n",
    "# convolution 층 6개, 완전 연결계층 2개 출력층 1개인 9층 신경망 \n",
    "\n",
    "model.summary()\n",
    "\n",
    "# 모델 훈련\n",
    "\n",
    "model_exists = False\n",
    "\n",
    "\n",
    "if model_exists:\n",
    "    \n",
    "    \n",
    "    model.load_weights('E:\\data10\\classification\\\\resultvgg9.h5')\n",
    "    \n",
    "    CLASSES = np.array(['개', '고슴도치' ]) \n",
    "    preds = model.predict( x_test[1:2] )   \n",
    "    preds_value = CLASSES[ np.argmax( preds, axis= -1 ) ] \n",
    "    actual_value = CLASSES[ np.argmax( y_test [1:2], axis = -1) ] \n",
    "    print ( preds_value)\n",
    "    print ( actual_value)\n",
    "    \n",
    "else:\n",
    "        \n",
    "    opt = Adam(lr=0.0005)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(x_train\n",
    "              , y_train\n",
    "              , batch_size=28\n",
    "              , epochs=50\n",
    "              , shuffle=True\n",
    "               , validation_data=(x_test,y_test) )\n",
    "    \n",
    "    \n",
    "    model.save_weights('E:\\data10\\classification\\\\resultvgg9.h5')\n",
    "    \n",
    "    model.evaluate(x_test, y_test, batch_size=28)\n",
    "    \n",
    "    CLASSES = np.array(['개', '고슴도치' ]) \n",
    "    preds = model.predict( x_test[1:2] )   \n",
    "    preds_value = CLASSES[ np.argmax( preds, axis= -1 ) ] \n",
    "    actual_value = CLASSES[ np.argmax( y_test[1:2], axis = -1) ] \n",
    "    print ( preds_value)\n",
    "    print ( actual_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ Another train.ver (vgg9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2606, 32, 32, 3)\n",
      "(2606, 2)\n",
      "(289, 32, 32, 3)\n",
      "(289, 2)\n",
      "(32, 32, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\ipykernel_launcher.py:75: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2606 samples, validate on 289 samples\n",
      "Epoch 1/100\n",
      " - 4s - loss: 0.8223 - accuracy: 0.6431 - val_loss: 0.7344 - val_accuracy: 0.6263\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.5682 - accuracy: 0.7452 - val_loss: 1.0176 - val_accuracy: 0.6263\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.4775 - accuracy: 0.7893 - val_loss: 0.5556 - val_accuracy: 0.7163\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.3787 - accuracy: 0.8304 - val_loss: 0.6027 - val_accuracy: 0.6574\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.3548 - accuracy: 0.8496 - val_loss: 0.4599 - val_accuracy: 0.7751\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.3263 - accuracy: 0.8661 - val_loss: 0.5025 - val_accuracy: 0.7924\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.4123 - accuracy: 0.8074 - val_loss: 0.5024 - val_accuracy: 0.7716\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.2984 - accuracy: 0.8711 - val_loss: 0.8088 - val_accuracy: 0.6817\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.3520 - accuracy: 0.8565 - val_loss: 0.4986 - val_accuracy: 0.7578\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.2651 - accuracy: 0.8872 - val_loss: 0.3744 - val_accuracy: 0.8270\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.2142 - accuracy: 0.9140 - val_loss: 0.4336 - val_accuracy: 0.8201\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.3054 - accuracy: 0.8699 - val_loss: 0.4138 - val_accuracy: 0.8062\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.2276 - accuracy: 0.9045 - val_loss: 0.4668 - val_accuracy: 0.7855\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.1862 - accuracy: 0.9244 - val_loss: 0.3099 - val_accuracy: 0.8754\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.2162 - accuracy: 0.9098 - val_loss: 0.4263 - val_accuracy: 0.8028\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.1796 - accuracy: 0.9256 - val_loss: 0.4200 - val_accuracy: 0.8028\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.1435 - accuracy: 0.9478 - val_loss: 0.3844 - val_accuracy: 0.8547\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.1844 - accuracy: 0.9217 - val_loss: 0.4006 - val_accuracy: 0.8304\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.2508 - accuracy: 0.8903 - val_loss: 0.7848 - val_accuracy: 0.7820\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.3737 - accuracy: 0.8450 - val_loss: 0.3299 - val_accuracy: 0.8408\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.1967 - accuracy: 0.9236 - val_loss: 0.3163 - val_accuracy: 0.8720\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.2188 - accuracy: 0.9140 - val_loss: 0.4482 - val_accuracy: 0.7751\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.1712 - accuracy: 0.9305 - val_loss: 0.3270 - val_accuracy: 0.8720\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.1237 - accuracy: 0.9524 - val_loss: 0.5230 - val_accuracy: 0.7612\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.2946 - accuracy: 0.8830 - val_loss: 1.0727 - val_accuracy: 0.6159\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.2951 - accuracy: 0.8699 - val_loss: 0.3982 - val_accuracy: 0.8270\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.2432 - accuracy: 0.8983 - val_loss: 0.3665 - val_accuracy: 0.8270\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.1471 - accuracy: 0.9405 - val_loss: 1.0292 - val_accuracy: 0.6644\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.1950 - accuracy: 0.9133 - val_loss: 0.3936 - val_accuracy: 0.8512\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.1311 - accuracy: 0.9447 - val_loss: 0.4682 - val_accuracy: 0.8443\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.2331 - accuracy: 0.9068 - val_loss: 0.4499 - val_accuracy: 0.8374\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.1542 - accuracy: 0.9371 - val_loss: 0.3882 - val_accuracy: 0.8547\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.2344 - accuracy: 0.8964 - val_loss: 0.3409 - val_accuracy: 0.8685\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.1667 - accuracy: 0.9321 - val_loss: 0.6254 - val_accuracy: 0.7405\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.2427 - accuracy: 0.8983 - val_loss: 0.4433 - val_accuracy: 0.8304\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.1367 - accuracy: 0.9470 - val_loss: 0.3765 - val_accuracy: 0.8616\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.1089 - accuracy: 0.9586 - val_loss: 0.3414 - val_accuracy: 0.8616\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.0914 - accuracy: 0.9647 - val_loss: 0.3373 - val_accuracy: 0.8685\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.0746 - accuracy: 0.9747 - val_loss: 0.3337 - val_accuracy: 0.8581\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.0824 - accuracy: 0.9693 - val_loss: 0.4576 - val_accuracy: 0.8028\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.1229 - accuracy: 0.9551 - val_loss: 0.5080 - val_accuracy: 0.7820\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.0819 - accuracy: 0.9697 - val_loss: 0.4882 - val_accuracy: 0.7855\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.0918 - accuracy: 0.9689 - val_loss: 0.3847 - val_accuracy: 0.8339\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.0821 - accuracy: 0.9739 - val_loss: 0.3842 - val_accuracy: 0.8616\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.0727 - accuracy: 0.9716 - val_loss: 0.3927 - val_accuracy: 0.8512\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.0476 - accuracy: 0.9873 - val_loss: 0.3801 - val_accuracy: 0.8651\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.0627 - accuracy: 0.9804 - val_loss: 0.4716 - val_accuracy: 0.8374\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.1877 - accuracy: 0.9286 - val_loss: 0.5763 - val_accuracy: 0.7612\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.1078 - accuracy: 0.9570 - val_loss: 0.4287 - val_accuracy: 0.8616\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.1824 - accuracy: 0.9252 - val_loss: 0.3893 - val_accuracy: 0.8651\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.1224 - accuracy: 0.9517 - val_loss: 0.4248 - val_accuracy: 0.8270\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.1031 - accuracy: 0.9616 - val_loss: 0.4896 - val_accuracy: 0.8166\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.1344 - accuracy: 0.9436 - val_loss: 0.5422 - val_accuracy: 0.8166\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.2025 - accuracy: 0.9194 - val_loss: 0.5026 - val_accuracy: 0.7993\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.0981 - accuracy: 0.9651 - val_loss: 0.3900 - val_accuracy: 0.8685\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.0700 - accuracy: 0.9731 - val_loss: 0.3235 - val_accuracy: 0.8720\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.0741 - accuracy: 0.9693 - val_loss: 0.3185 - val_accuracy: 0.8824\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.0563 - accuracy: 0.9812 - val_loss: 0.3712 - val_accuracy: 0.8754\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.2361 - accuracy: 0.9106 - val_loss: 0.4134 - val_accuracy: 0.8062\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.1244 - accuracy: 0.9520 - val_loss: 0.3870 - val_accuracy: 0.8166\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.0990 - accuracy: 0.9639 - val_loss: 0.4064 - val_accuracy: 0.8339\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.0790 - accuracy: 0.9708 - val_loss: 0.3533 - val_accuracy: 0.8304\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.0669 - accuracy: 0.9770 - val_loss: 0.3651 - val_accuracy: 0.8754\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.0604 - accuracy: 0.9777 - val_loss: 0.3846 - val_accuracy: 0.8616\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.0590 - accuracy: 0.9800 - val_loss: 0.3799 - val_accuracy: 0.8616\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.1067 - accuracy: 0.9589 - val_loss: 0.7440 - val_accuracy: 0.7232\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.0798 - accuracy: 0.9712 - val_loss: 0.5201 - val_accuracy: 0.8131\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.0759 - accuracy: 0.9724 - val_loss: 0.3468 - val_accuracy: 0.8616\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.0549 - accuracy: 0.9797 - val_loss: 0.3901 - val_accuracy: 0.8616\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.0572 - accuracy: 0.9789 - val_loss: 0.3699 - val_accuracy: 0.8754\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.0582 - accuracy: 0.9766 - val_loss: 0.3979 - val_accuracy: 0.8408\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.0793 - accuracy: 0.9701 - val_loss: 0.4317 - val_accuracy: 0.8374\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.0574 - accuracy: 0.9816 - val_loss: 0.4696 - val_accuracy: 0.8408\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.0504 - accuracy: 0.9816 - val_loss: 0.6548 - val_accuracy: 0.7889\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.0407 - accuracy: 0.9858 - val_loss: 0.4130 - val_accuracy: 0.8547\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.0543 - accuracy: 0.9816 - val_loss: 0.4332 - val_accuracy: 0.8478\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.0336 - accuracy: 0.9866 - val_loss: 0.7976 - val_accuracy: 0.7543\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.0281 - accuracy: 0.9912 - val_loss: 0.4301 - val_accuracy: 0.8651\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.0368 - accuracy: 0.9896 - val_loss: 0.4171 - val_accuracy: 0.8651\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.1531 - accuracy: 0.9421 - val_loss: 0.6187 - val_accuracy: 0.7924\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.0732 - accuracy: 0.9716 - val_loss: 0.4175 - val_accuracy: 0.8339\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.0851 - accuracy: 0.9685 - val_loss: 0.5335 - val_accuracy: 0.8443\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.0613 - accuracy: 0.9754 - val_loss: 0.3845 - val_accuracy: 0.8616\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.0365 - accuracy: 0.9862 - val_loss: 0.4134 - val_accuracy: 0.8581\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.1515 - accuracy: 0.9478 - val_loss: 0.4045 - val_accuracy: 0.8547\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.1394 - accuracy: 0.9547 - val_loss: 0.3505 - val_accuracy: 0.8616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/100\n",
      " - 1s - loss: 0.0636 - accuracy: 0.9793 - val_loss: 0.4072 - val_accuracy: 0.8270\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.0482 - accuracy: 0.9800 - val_loss: 0.4236 - val_accuracy: 0.8201\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.0420 - accuracy: 0.9843 - val_loss: 0.3858 - val_accuracy: 0.8304\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.0755 - accuracy: 0.9731 - val_loss: 0.3381 - val_accuracy: 0.8789\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.0524 - accuracy: 0.9843 - val_loss: 0.4556 - val_accuracy: 0.8443\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.0318 - accuracy: 0.9893 - val_loss: 0.4470 - val_accuracy: 0.8408\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.0396 - accuracy: 0.9862 - val_loss: 0.5352 - val_accuracy: 0.8131\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.0259 - accuracy: 0.9919 - val_loss: 0.3748 - val_accuracy: 0.8789\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.0305 - accuracy: 0.9908 - val_loss: 0.7548 - val_accuracy: 0.7647\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.2531 - accuracy: 0.9163 - val_loss: 0.5505 - val_accuracy: 0.7958\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.0954 - accuracy: 0.9609 - val_loss: 0.5205 - val_accuracy: 0.8374\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.0834 - accuracy: 0.9670 - val_loss: 0.4117 - val_accuracy: 0.8685\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.0632 - accuracy: 0.9785 - val_loss: 0.3732 - val_accuracy: 0.8893\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.1191 - accuracy: 0.9517 - val_loss: 0.4730 - val_accuracy: 0.8270\n",
      "CNN Error: 17.30%\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential, save_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import loader3\n",
    "\n",
    "batch_size = 28\n",
    "num_classes = 2\n",
    "epochs = 100\n",
    " \n",
    "train_image='E:\\\\data10\\\\classification\\\\train_resize\\\\'\n",
    "train_label= 'E:\\\\data10\\\\classification\\\\train_label.csv'\n",
    "test_image='E:\\\\data10\\\\classification\\\\test_resize\\\\'\n",
    "test_label='E:\\\\data10\\\\classification\\\\test_label.csv'\n",
    "\n",
    "\n",
    "x_train = loader3.image_load(train_image)\n",
    "y_train = loader3.label_load(train_label)\n",
    "x_test = loader3.image_load(test_image)\n",
    "y_test = loader3.label_load(test_label)      \n",
    "\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(x_train.shape[1:])\n",
    "\n",
    "#(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "# One hot Encoding\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:]))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    " \n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    " \n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    " \n",
    "hist = model.fit(x_train, y_train, validation_data=(x_test, y_test), nb_epoch=epochs, batch_size=batch_size, verbose=2)\n",
    " \n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))\n",
    " \n",
    "save_model(model, \"E:\\data10\\classification\\models\\\\result2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ Vgg16.ver test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2606, 32, 32, 3)\n",
      "(2606, 2)\n",
      "(289, 32, 32, 3)\n",
      "(289, 2)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_29 (LeakyReLU)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_30 (LeakyReLU)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 8194      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 33,655,106\n",
      "Trainable params: 33,630,274\n",
      "Non-trainable params: 24,832\n",
      "_________________________________________________________________\n",
      "Train on 2606 samples, validate on 289 samples\n",
      "Epoch 1/50\n",
      "2606/2606 [==============================] - 9s 3ms/step - loss: 1.1824 - accuracy: 0.5702 - val_loss: 10.9036 - val_accuracy: 0.3668\n",
      "Epoch 2/50\n",
      "2606/2606 [==============================] - 4s 2ms/step - loss: 0.7623 - accuracy: 0.6466 - val_loss: 0.6038 - val_accuracy: 0.6990\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2606/2606 [==============================] - 4s 2ms/step - loss: 0.6150 - accuracy: 0.7421 - val_loss: 0.8588 - val_accuracy: 0.7612\n",
      "Epoch 4/50\n",
      "2606/2606 [==============================] - 4s 2ms/step - loss: 0.5067 - accuracy: 0.7905 - val_loss: 0.5669 - val_accuracy: 0.7474\n",
      "Epoch 5/50\n",
      "2606/2606 [==============================] - 4s 2ms/step - loss: 0.5223 - accuracy: 0.7832 - val_loss: 0.5694 - val_accuracy: 0.8512\n",
      "Epoch 6/50\n",
      "2606/2606 [==============================] - 4s 2ms/step - loss: 0.3954 - accuracy: 0.8384 - val_loss: 1.0754 - val_accuracy: 0.6574\n",
      "Epoch 7/50\n",
      "2606/2606 [==============================] - 4s 2ms/step - loss: 0.3298 - accuracy: 0.8726 - val_loss: 0.7112 - val_accuracy: 0.7751\n",
      "Epoch 8/50\n",
      "2606/2606 [==============================] - 4s 2ms/step - loss: 0.2801 - accuracy: 0.8949 - val_loss: 0.6461 - val_accuracy: 0.7889\n",
      "Epoch 9/50\n",
      "2606/2606 [==============================] - 4s 2ms/step - loss: 0.2269 - accuracy: 0.9079 - val_loss: 0.7932 - val_accuracy: 0.7889\n",
      "Epoch 10/50\n",
      "2606/2606 [==============================] - 4s 2ms/step - loss: 0.2078 - accuracy: 0.9263 - val_loss: 4.3793 - val_accuracy: 0.7266\n",
      "Epoch 11/50\n",
      "2606/2606 [==============================] - 4s 2ms/step - loss: 0.2139 - accuracy: 0.9163 - val_loss: 0.6267 - val_accuracy: 0.8166\n",
      "Epoch 12/50\n",
      "2606/2606 [==============================] - 4s 2ms/step - loss: 0.1739 - accuracy: 0.9351 - val_loss: 0.6451 - val_accuracy: 0.7889\n",
      "Epoch 13/50\n",
      "2606/2606 [==============================] - 4s 2ms/step - loss: 0.3106 - accuracy: 0.8876 - val_loss: 1.0739 - val_accuracy: 0.8166\n",
      "Epoch 14/50\n",
      "2606/2606 [==============================] - 4s 2ms/step - loss: 0.1362 - accuracy: 0.9513 - val_loss: 0.6293 - val_accuracy: 0.7924\n",
      "Epoch 15/50\n",
      "2606/2606 [==============================] - 4s 2ms/step - loss: 0.1420 - accuracy: 0.9455 - val_loss: 0.4775 - val_accuracy: 0.8374\n",
      "Epoch 16/50\n",
      "2606/2606 [==============================] - 4s 2ms/step - loss: 0.1272 - accuracy: 0.9532 - val_loss: 0.4613 - val_accuracy: 0.8408\n",
      "Epoch 17/50\n",
      "2606/2606 [==============================] - 4s 2ms/step - loss: 0.1091 - accuracy: 0.9624 - val_loss: 3.0730 - val_accuracy: 0.4948\n",
      "Epoch 18/50\n",
      "2606/2606 [==============================] - 4s 2ms/step - loss: 0.9320 - accuracy: 0.5756 - val_loss: 58.6346 - val_accuracy: 0.3737\n",
      "Epoch 19/50\n",
      "2606/2606 [==============================] - 4s 2ms/step - loss: 0.9085 - accuracy: 0.5591 - val_loss: 2.6476 - val_accuracy: 0.4048\n",
      "Epoch 20/50\n",
      "2606/2606 [==============================] - 4s 2ms/step - loss: 0.7853 - accuracy: 0.5860 - val_loss: 0.7725 - val_accuracy: 0.6194.7812 - ac\n",
      "Epoch 21/50\n",
      "2606/2606 [==============================] - 4s 2ms/step - loss: 0.8004 - accuracy: 0.6163 - val_loss: 0.6805 - val_accuracy: 0.6159\n",
      "Epoch 22/50\n",
      "2606/2606 [==============================] - 4s 2ms/step - loss: 0.7366 - accuracy: 0.6520 - val_loss: 0.7862 - val_accuracy: 0.5952\n",
      "Epoch 23/50\n",
      "2606/2606 [==============================] - 4s 2ms/step - loss: 0.5490 - accuracy: 0.7322 - val_loss: 0.5373 - val_accuracy: 0.7439\n",
      "Epoch 24/50\n",
      "2606/2606 [==============================] - 4s 2ms/step - loss: 0.5085 - accuracy: 0.7882 - val_loss: 0.9480 - val_accuracy: 0.5709\n",
      "Epoch 25/50\n",
      "2606/2606 [==============================] - 4s 2ms/step - loss: 0.8351 - accuracy: 0.5979 - val_loss: 2.0994 - val_accuracy: 0.4048\n",
      "Epoch 26/50\n",
      "2606/2606 [==============================] - 4s 2ms/step - loss: 0.7226 - accuracy: 0.6531 - val_loss: 1.5922 - val_accuracy: 0.5087\n",
      "Epoch 27/50\n",
      "2606/2606 [==============================] - 4s 2ms/step - loss: 0.6298 - accuracy: 0.7091 - val_loss: 0.4591 - val_accuracy: 0.7993\n",
      "Epoch 28/50\n",
      "2606/2606 [==============================] - 4s 2ms/step - loss: 0.5557 - accuracy: 0.7590 - val_loss: 2.4313 - val_accuracy: 0.3841\n",
      "Epoch 29/50\n",
      "2606/2606 [==============================] - 4s 2ms/step - loss: 0.8425 - accuracy: 0.5779 - val_loss: 0.9583 - val_accuracy: 0.6332\n",
      "Epoch 30/50\n",
      "2606/2606 [==============================] - 4s 2ms/step - loss: 0.7840 - accuracy: 0.5790 - val_loss: 0.9267 - val_accuracy: 0.6367\n",
      "Epoch 31/50\n",
      "2606/2606 [==============================] - 4s 2ms/step - loss: 0.7530 - accuracy: 0.5833 - val_loss: 0.9524 - val_accuracy: 0.6055\n",
      "Epoch 32/50\n",
      "2606/2606 [==============================] - 5s 2ms/step - loss: 0.7619 - accuracy: 0.6067 - val_loss: 0.7217 - val_accuracy: 0.5882\n",
      "Epoch 33/50\n",
      "2606/2606 [==============================] - 4s 2ms/step - loss: 0.7133 - accuracy: 0.6178 - val_loss: 0.6907 - val_accuracy: 0.6055\n",
      "Epoch 34/50\n",
      "2606/2606 [==============================] - 4s 2ms/step - loss: 0.7035 - accuracy: 0.6339 - val_loss: 0.6684 - val_accuracy: 0.6298\n",
      "Epoch 35/50\n",
      "2606/2606 [==============================] - 4s 2ms/step - loss: 0.6601 - accuracy: 0.6577 - val_loss: 0.6341 - val_accuracy: 0.6228\n",
      "Epoch 36/50\n",
      "2606/2606 [==============================] - 4s 2ms/step - loss: 0.6414 - accuracy: 0.6788 - val_loss: 0.5881 - val_accuracy: 0.6747\n",
      "Epoch 37/50\n",
      "2606/2606 [==============================] - 4s 2ms/step - loss: 0.5881 - accuracy: 0.7114 - val_loss: 0.6249 - val_accuracy: 0.6263\n",
      "Epoch 38/50\n",
      "2606/2606 [==============================] - 4s 2ms/step - loss: 0.5573 - accuracy: 0.7279 - val_loss: 0.4793 - val_accuracy: 0.7751\n",
      "Epoch 39/50\n",
      "2606/2606 [==============================] - 4s 2ms/step - loss: 0.5724 - accuracy: 0.7299 - val_loss: 0.4853 - val_accuracy: 0.7855\n",
      "Epoch 40/50\n",
      "2606/2606 [==============================] - 4s 2ms/step - loss: 0.5158 - accuracy: 0.7621 - val_loss: 0.4675 - val_accuracy: 0.8028\n",
      "Epoch 41/50\n",
      "2606/2606 [==============================] - 4s 2ms/step - loss: 0.4874 - accuracy: 0.7847 - val_loss: 0.4187 - val_accuracy: 0.8028\n",
      "Epoch 42/50\n",
      "2606/2606 [==============================] - 4s 2ms/step - loss: 0.4755 - accuracy: 0.7993 - val_loss: 0.5029 - val_accuracy: 0.7682\n",
      "Epoch 43/50\n",
      "2606/2606 [==============================] - 4s 2ms/step - loss: 0.4634 - accuracy: 0.8039 - val_loss: 0.4736 - val_accuracy: 0.7509\n",
      "Epoch 44/50\n",
      "2606/2606 [==============================] - 4s 2ms/step - loss: 0.4122 - accuracy: 0.8285 - val_loss: 0.4343 - val_accuracy: 0.8097\n",
      "Epoch 45/50\n",
      "2606/2606 [==============================] - 4s 2ms/step - loss: 0.4359 - accuracy: 0.8078 - val_loss: 0.3762 - val_accuracy: 0.8270\n",
      "Epoch 46/50\n",
      "2606/2606 [==============================] - 4s 2ms/step - loss: 0.3973 - accuracy: 0.8377 - val_loss: 0.3715 - val_accuracy: 0.8374\n",
      "Epoch 47/50\n",
      "2606/2606 [==============================] - 4s 2ms/step - loss: 0.4048 - accuracy: 0.8281 - val_loss: 0.3822 - val_accuracy: 0.8304\n",
      "Epoch 48/50\n",
      "2606/2606 [==============================] - 4s 2ms/step - loss: 0.3595 - accuracy: 0.8515 - val_loss: 0.3906 - val_accuracy: 0.8235\n",
      "Epoch 49/50\n",
      "2606/2606 [==============================] - 4s 2ms/step - loss: 0.3552 - accuracy: 0.8546 - val_loss: 0.4835 - val_accuracy: 0.7751\n",
      "Epoch 50/50\n",
      "2606/2606 [==============================] - 4s 2ms/step - loss: 0.3367 - accuracy: 0.8557 - val_loss: 0.3962 - val_accuracy: 0.8097\n",
      "289/289 [==============================] - 0s 352us/step\n",
      "['고슴도치']\n",
      "['고슴도치']\n"
     ]
    }
   ],
   "source": [
    "import os, cv2, random\n",
    "\n",
    "# 필요한 라이브러리 import 하는 코드 \n",
    "import numpy as np\n",
    "\n",
    "from keras.layers import Input, Flatten, Dense, Conv2D, BatchNormalization, LeakyReLU, Dropout, Activation, MaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K   # 백엔드가  텐서 플로우로 되어있어서 \n",
    "                                     # 텐서 플로우 명령어 필요할 때 tf 대신에 \n",
    "                                     # k 를 쓰겠다라는 의미 \n",
    "\n",
    "import loader3\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "train_image='E:\\\\data10\\\\classification\\\\train_resize\\\\'\n",
    "train_label= 'E:\\\\data10\\\\classification\\\\train_label.csv'\n",
    "test_image='E:\\\\data10\\\\classification\\\\test_resize\\\\'\n",
    "test_label='E:\\\\data10\\\\classification\\\\test_label.csv'\n",
    "\n",
    "print(loader3.image_load(train_image).shape)\n",
    "print(loader3.label_load(train_label).shape)\n",
    "print(loader3.image_load(test_image).shape)\n",
    "print(loader3.label_load(test_label).shape)\n",
    "\n",
    "x_train = loader3.image_load(train_image)\n",
    "y_train = loader3.label_load(train_label)\n",
    "x_test = loader3.image_load(test_image)\n",
    "y_test = loader3.label_load(test_label)\n",
    "\n",
    "# 모델 만들기\n",
    "input_layer = Input((32,32,3))\n",
    "\n",
    "x = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same')(input_layer)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = MaxPooling2D(pool_size = 2, strides = 2)(x)\n",
    "\n",
    "x = Conv2D(filters = 128, kernel_size = 3, strides = 1, padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2D(filters = 128, kernel_size = 3, strides = 1, padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = MaxPooling2D(pool_size = 2, strides = 2)(x)\n",
    "\n",
    "x = Conv2D(filters = 256, kernel_size = 3, strides = 1, padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2D(filters = 256, kernel_size = 3, strides = 1, padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2D(filters = 256, kernel_size = 3, strides = 1, padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = MaxPooling2D(pool_size = 2, strides = 2)(x)\n",
    "\n",
    "x = Conv2D(filters = 512, kernel_size = 3, strides = 1, padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2D(filters = 512, kernel_size = 3, strides = 1, padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2D(filters = 512, kernel_size = 3, strides = 1, padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = MaxPooling2D(pool_size = 2, strides = 2)(x)\n",
    "\n",
    "x = Conv2D(filters = 512, kernel_size = 3, strides = 1, padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2D(filters = 512, kernel_size = 3, strides = 1, padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2D(filters = 512, kernel_size = 3, strides = 1, padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = MaxPooling2D(pool_size = 2, strides = 2)(x)\n",
    "\n",
    "# 완전 연결 계층\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dense(4096)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(rate = 0.5)(x)\n",
    "\n",
    "x = Dense(4096)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(rate = 0.5)(x)\n",
    "\n",
    "x = Dense(NUM_CLASSES)(x)\n",
    "output_layer = Activation('softmax')(x)\n",
    "\n",
    "model = Model(input_layer, output_layer)\n",
    "\n",
    "# convolution 층 5개, 완전 연결계층 3개인 8층 신경망\n",
    "model.summary()\n",
    "\n",
    "# 모델 훈련\n",
    "\n",
    "model_exists = False\n",
    "\n",
    "\n",
    "if model_exists:\n",
    "    \n",
    "    \n",
    "    model.load_weights('E:\\data10\\classification\\\\resultvgg9.h5')\n",
    "    \n",
    "    CLASSES = np.array(['개', '고슴도치' ]) \n",
    "    preds = model.predict( x_test[1:2] )   \n",
    "    preds_value = CLASSES[ np.argmax( preds, axis= -1 ) ] \n",
    "    actual_value = CLASSES[ np.argmax( y_test [1:2], axis = -1) ] \n",
    "    print ( preds_value)\n",
    "    print ( actual_value)\n",
    "    \n",
    "else:\n",
    "        \n",
    "    opt = Adam(lr=0.0005)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(x_train\n",
    "              , y_train\n",
    "              , batch_size=28\n",
    "              , epochs=50\n",
    "              , shuffle=True\n",
    "               , validation_data=(x_test,y_test) )\n",
    "    \n",
    "    \n",
    "    model.save_weights('E:\\data10\\classification\\\\resultvgg16.h5')\n",
    "    \n",
    "    model.evaluate(x_test, y_test, batch_size=28)\n",
    "    \n",
    "    CLASSES = np.array(['개', '고슴도치' ]) \n",
    "    preds = model.predict( x_test[1:2] )   \n",
    "    preds_value = CLASSES[ np.argmax( preds, axis= -1 ) ] \n",
    "    actual_value = CLASSES[ np.argmax( y_test[1:2], axis = -1) ] \n",
    "    print ( preds_value)\n",
    "    print ( actual_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf2.0-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
