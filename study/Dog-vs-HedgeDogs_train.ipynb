{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ Image Files resize (32x32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 # 이미지나 영상을 처리하는 모듈\n",
    "\n",
    "path = [\"E:\\data10\\classification\\dogs\"] \n",
    "# E:\\data10\\classification\\dogs \n",
    "# E:\\data10\\classification\\hedgedogs\n",
    "\n",
    "j = 0\n",
    "for k in path:\n",
    "    file_list = os.listdir(k)\n",
    "    file_name = []\n",
    "    for i in file_list:\n",
    "        if  i not in ['resized_2.jpg','resized_3.jpg','resized_4.jpg']:\n",
    "            file_name.append(int( i[:-4] ))\n",
    "    file_name.sort()\n",
    "    file_list = [k + '\\\\' + str(i) + '.jpg' for i in file_name]\n",
    "    \n",
    "    for i in file_list:\n",
    "        img = cv2.imread(i)\n",
    "        width, height = img.shape[:2]\n",
    "        resize = cv2.resize(img, (int(32), int(32)), interpolation=cv2.INTER_CUBIC) # 현재 32 x 32로 resize\n",
    "        cv2.imwrite(\"d:\\\\resize\\\\\" + str(j + 1) + '.jpg', resize)\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ Create Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'E:\\data10\\classification\\\\train_label.csv'\n",
    "file = open( path, 'w')\n",
    "for  i  in  range(1, 1630):\n",
    "    file.write( str(1) + '\\n' )\n",
    "for  i  in  range(1, 978):\n",
    "    file.write( str(0) + '\\n') \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'E:\\data10\\classification\\\\test_label.csv'\n",
    "file = open( path, 'w')\n",
    "for  i  in  range(1, 182):\n",
    "    file.write( str(1) + '\\n' )\n",
    "for  i  in  range(1, 109):\n",
    "     file.write( str(0) + '\\n') \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ Create loader3.py \n",
    "\n",
    " ■ image_load  \n",
    " ■ next_batch  \n",
    " ■ shuffle_batch  \n",
    " ■ label_load  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  csv\n",
    "import  os\n",
    "import  re\n",
    "import  cv2\n",
    "import  random\n",
    "import  numpy  as  np\n",
    "\n",
    "def  image_load(path):\n",
    "    file_list = os.listdir(path)\n",
    "    file_name = []\n",
    "    for  i  in  file_list:\n",
    "        a = int(  re.sub('[^0-9]', '', i )  ) # 숫자가 아닌것은 '' 로 처리 \n",
    "        file_name.append(a) \n",
    "    file_name.sort()\n",
    "\n",
    "    file_res = [] \n",
    "    for  j  in   file_name:\n",
    "        file_res.append('%s\\\\%d.jpg' %(path,j)  )\n",
    "\n",
    "    image = []\n",
    "    for  k  in  file_res:\n",
    "        img = cv2.imread(k)\n",
    "        image.append(img)\n",
    "\n",
    "    return  np.array(image)\n",
    "\n",
    "def  label_load( path ):\n",
    "    file = open(path)\n",
    "    labeldata = csv.reader(file)\n",
    "    labellist = []\n",
    "    for  i   in  labeldata:\n",
    "        labellist.append(i)\n",
    "\n",
    "    label = np.array(labellist)\n",
    "    label = label.astype(int)  # 숫자로 변환 \n",
    "    label = np.eye(2)[label]\n",
    "    label = label.reshape(-1,2) \n",
    "    return  label\n",
    "\n",
    "\n",
    "def  shuffle_batch( data_list, label ):\n",
    "    x = np.arange( len( data_list) )\n",
    "    random.shuffle(x)\n",
    "    data_list2 = data_list[x]\n",
    "    label2 = label[x]\n",
    "    return   data_list2, label2 \n",
    "\n",
    "\n",
    "def  next_batch( data1, data2, init,  fina ):\n",
    "    return  data1[ init : fina ],  data2[init : fina] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2606, 32, 32, 3)\n",
      "(2606, 2)\n",
      "(289, 32, 32, 3)\n",
      "(289, 2)\n"
     ]
    }
   ],
   "source": [
    "import loader3\n",
    "\n",
    "train_image='E:\\\\data10\\\\classification\\\\train_resize\\\\'\n",
    "train_label= 'E:\\\\data10\\\\classification\\\\train_label.csv'\n",
    "test_image='E:\\\\data10\\\\classification\\\\test_resize\\\\'\n",
    "test_label='E:\\\\data10\\\\classification\\\\test_label.csv'\n",
    "\n",
    "print(loader3.image_load(train_image).shape)\n",
    "print(loader3.label_load(train_label).shape)\n",
    "print(loader3.image_load(test_image).shape)\n",
    "print(loader3.label_load(test_label).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ Train start (vgg9.ver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2, random\n",
    "\n",
    "# 필요한 라이브러리 import 하는 코드 \n",
    "import numpy as np\n",
    "\n",
    "from keras.layers import Input, Flatten, Dense, Conv2D, BatchNormalization, LeakyReLU, Dropout, Activation, MaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K   # 백엔드가  텐서 플로우로 되어있어서 \n",
    "                                     # 텐서 플로우 명령어 필요할 때 tf 대신에 \n",
    "                                     # k 를 쓰겠다라는 의미 \n",
    "\n",
    "import loader3\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "train_image='E:\\\\data10\\\\classification\\\\train_resize\\\\'\n",
    "train_label= 'E:\\\\data10\\\\classification\\\\train_label.csv'\n",
    "test_image='E:\\\\data10\\\\classification\\\\test_resize\\\\'\n",
    "test_label='E:\\\\data10\\\\classification\\\\test_label.csv'\n",
    "\n",
    "print(loader3.image_load(train_image).shape)\n",
    "print(loader3.label_load(train_label).shape)\n",
    "print(loader3.image_load(test_image).shape)\n",
    "print(loader3.label_load(test_label).shape)\n",
    "\n",
    "x_train = loader3.image_load(train_image)\n",
    "y_train = loader3.label_load(train_label)\n",
    "x_test = loader3.image_load(test_image)\n",
    "y_test = loader3.label_load(test_label)\n",
    "\n",
    "\n",
    "# 모델 만들기 \n",
    "input_layer = Input((32,32,3))\n",
    "\n",
    "x = Conv2D(filters = 128, kernel_size = 3, strides = 1, padding = 'same')(input_layer)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(rate = 0.5)(x)\n",
    "\n",
    "x = Conv2D(filters = 128, kernel_size = 3, strides = 1, padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(rate = 0.5)(x)\n",
    "x = MaxPooling2D(pool_size=2,strides=2)(x)\n",
    "\n",
    "\n",
    "x = Conv2D(filters = 256, kernel_size = 3, strides = 1, padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(rate = 0.5)(x)\n",
    "\n",
    "x = Conv2D(filters = 256, kernel_size = 3, strides = 1, padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(rate = 0.5)(x)\n",
    "\n",
    "x = MaxPooling2D(pool_size=2,strides=2)(x)\n",
    "\n",
    "\n",
    "x = Conv2D(filters = 512, kernel_size = 3, strides = 1, padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(rate = 0.5)(x)\n",
    "\n",
    "x = Conv2D(filters = 512, kernel_size = 3, strides = 1, padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(rate = 0.5)(x)\n",
    "\n",
    "x = MaxPooling2D(pool_size=2,strides=2)(x)\n",
    "\n",
    "\n",
    "\n",
    "# 완전 연결 계층 \n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dense(1024)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(rate = 0.5)(x)\n",
    "\n",
    "x = Dense(1024)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(rate = 0.5)(x)\n",
    "\n",
    "x = Dense(NUM_CLASSES)(x)\n",
    "output_layer = Activation('softmax')(x)\n",
    "\n",
    "model = Model(input_layer, output_layer)\n",
    "\n",
    "# convolution 층 6개, 완전 연결계층 2개 출력층 1개인 9층 신경망 \n",
    "\n",
    "model.summary()\n",
    "\n",
    "# 모델 훈련\n",
    "\n",
    "model_exists = False\n",
    "\n",
    "\n",
    "if model_exists:\n",
    "    \n",
    "    \n",
    "    model.load_weights('E:\\data10\\classification\\\\resultvgg9.h5')\n",
    "    \n",
    "    CLASSES = np.array(['개', '고슴도치' ]) \n",
    "    preds = model.predict( x_test[1:2] )   \n",
    "    preds_value = CLASSES[ np.argmax( preds, axis= -1 ) ] \n",
    "    actual_value = CLASSES[ np.argmax( y_test [1:2], axis = -1) ] \n",
    "    print ( preds_value)\n",
    "    print ( actual_value)\n",
    "    \n",
    "else:\n",
    "        \n",
    "    opt = Adam(lr=0.0005)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(x_train\n",
    "              , y_train\n",
    "              , batch_size=28\n",
    "              , epochs=50\n",
    "              , shuffle=True\n",
    "               , validation_data=(x_test,y_test) )\n",
    "    \n",
    "    \n",
    "    model.save_weights('E:\\data10\\classification\\\\resultvgg9.h5')\n",
    "    \n",
    "    model.evaluate(x_test, y_test, batch_size=28)\n",
    "    \n",
    "    CLASSES = np.array(['개', '고슴도치' ]) \n",
    "    preds = model.predict( x_test[1:2] )   \n",
    "    preds_value = CLASSES[ np.argmax( preds, axis= -1 ) ] \n",
    "    actual_value = CLASSES[ np.argmax( y_test[1:2], axis = -1) ] \n",
    "    print ( preds_value)\n",
    "    print ( actual_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ Another train.ver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2606, 32, 32, 3)\n",
      "(2606, 2)\n",
      "(289, 32, 32, 3)\n",
      "(289, 2)\n",
      "(32, 32, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\ipykernel_launcher.py:75: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2606 samples, validate on 289 samples\n",
      "Epoch 1/100\n",
      " - 4s - loss: 0.8953 - accuracy: 0.6132 - val_loss: 0.8038 - val_accuracy: 0.3841\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.5820 - accuracy: 0.7352 - val_loss: 0.6578 - val_accuracy: 0.5917\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.4914 - accuracy: 0.7774 - val_loss: 0.6289 - val_accuracy: 0.6332\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.4247 - accuracy: 0.8139 - val_loss: 0.8937 - val_accuracy: 0.4844\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.4313 - accuracy: 0.8016 - val_loss: 0.4783 - val_accuracy: 0.7301\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.3642 - accuracy: 0.8342 - val_loss: 0.3824 - val_accuracy: 0.8270\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.3474 - accuracy: 0.8492 - val_loss: 0.3359 - val_accuracy: 0.8685\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.2876 - accuracy: 0.8776 - val_loss: 0.4585 - val_accuracy: 0.7682\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.3016 - accuracy: 0.8730 - val_loss: 0.3625 - val_accuracy: 0.8339\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.2260 - accuracy: 0.9037 - val_loss: 0.3277 - val_accuracy: 0.8512\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.1987 - accuracy: 0.9156 - val_loss: 0.3640 - val_accuracy: 0.8201\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.1708 - accuracy: 0.9282 - val_loss: 0.3774 - val_accuracy: 0.8304\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.1982 - accuracy: 0.9236 - val_loss: 0.5218 - val_accuracy: 0.7993\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.2009 - accuracy: 0.9160 - val_loss: 0.3543 - val_accuracy: 0.8547\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.2232 - accuracy: 0.9064 - val_loss: 0.5238 - val_accuracy: 0.8235\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.2014 - accuracy: 0.9171 - val_loss: 0.3537 - val_accuracy: 0.8547\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.1667 - accuracy: 0.9332 - val_loss: 0.3884 - val_accuracy: 0.8166\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.1292 - accuracy: 0.9497 - val_loss: 0.3031 - val_accuracy: 0.8651\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.2198 - accuracy: 0.9106 - val_loss: 0.4444 - val_accuracy: 0.8512\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.1349 - accuracy: 0.9470 - val_loss: 0.3554 - val_accuracy: 0.8685\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.2449 - accuracy: 0.9029 - val_loss: 0.3265 - val_accuracy: 0.8443\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.1508 - accuracy: 0.9390 - val_loss: 0.3514 - val_accuracy: 0.8408\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.1096 - accuracy: 0.9589 - val_loss: 0.3597 - val_accuracy: 0.8443\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.1273 - accuracy: 0.9528 - val_loss: 0.3653 - val_accuracy: 0.8235\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.1392 - accuracy: 0.9432 - val_loss: 0.9309 - val_accuracy: 0.7024\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.1069 - accuracy: 0.9609 - val_loss: 0.3178 - val_accuracy: 0.8824\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.0918 - accuracy: 0.9655 - val_loss: 0.3613 - val_accuracy: 0.8685\n",
      "Epoch 28/100\n",
      " - 1s - loss: 0.0671 - accuracy: 0.9751 - val_loss: 0.5489 - val_accuracy: 0.8270\n",
      "Epoch 29/100\n",
      " - 1s - loss: 0.1093 - accuracy: 0.9547 - val_loss: 0.4702 - val_accuracy: 0.8062\n",
      "Epoch 30/100\n",
      " - 1s - loss: 0.0618 - accuracy: 0.9785 - val_loss: 0.5088 - val_accuracy: 0.8131\n",
      "Epoch 31/100\n",
      " - 1s - loss: 0.0631 - accuracy: 0.9777 - val_loss: 0.4013 - val_accuracy: 0.8581\n",
      "Epoch 32/100\n",
      " - 1s - loss: 0.1785 - accuracy: 0.9317 - val_loss: 0.5119 - val_accuracy: 0.8097\n",
      "Epoch 33/100\n",
      " - 1s - loss: 0.0884 - accuracy: 0.9658 - val_loss: 0.3781 - val_accuracy: 0.8581\n",
      "Epoch 34/100\n",
      " - 1s - loss: 0.2885 - accuracy: 0.8891 - val_loss: 0.3903 - val_accuracy: 0.8581\n",
      "Epoch 35/100\n",
      " - 1s - loss: 0.1651 - accuracy: 0.9359 - val_loss: 0.3643 - val_accuracy: 0.8512\n",
      "Epoch 36/100\n",
      " - 1s - loss: 0.1901 - accuracy: 0.9271 - val_loss: 0.3613 - val_accuracy: 0.8685\n",
      "Epoch 37/100\n",
      " - 1s - loss: 0.1089 - accuracy: 0.9601 - val_loss: 0.4751 - val_accuracy: 0.8304\n",
      "Epoch 38/100\n",
      " - 1s - loss: 0.0961 - accuracy: 0.9624 - val_loss: 0.6768 - val_accuracy: 0.7612\n",
      "Epoch 39/100\n",
      " - 1s - loss: 0.0881 - accuracy: 0.9647 - val_loss: 0.3458 - val_accuracy: 0.8720\n",
      "Epoch 40/100\n",
      " - 1s - loss: 0.0788 - accuracy: 0.9716 - val_loss: 0.3894 - val_accuracy: 0.8478\n",
      "Epoch 41/100\n",
      " - 1s - loss: 0.1337 - accuracy: 0.9493 - val_loss: 0.3527 - val_accuracy: 0.8547\n",
      "Epoch 42/100\n",
      " - 1s - loss: 0.0777 - accuracy: 0.9697 - val_loss: 0.4313 - val_accuracy: 0.8304\n",
      "Epoch 43/100\n",
      " - 1s - loss: 0.0512 - accuracy: 0.9816 - val_loss: 0.3716 - val_accuracy: 0.8720\n",
      "Epoch 44/100\n",
      " - 1s - loss: 0.0680 - accuracy: 0.9735 - val_loss: 0.4211 - val_accuracy: 0.8581\n",
      "Epoch 45/100\n",
      " - 1s - loss: 0.0413 - accuracy: 0.9850 - val_loss: 0.3956 - val_accuracy: 0.8651\n",
      "Epoch 46/100\n",
      " - 1s - loss: 0.0531 - accuracy: 0.9793 - val_loss: 0.3357 - val_accuracy: 0.8685\n",
      "Epoch 47/100\n",
      " - 1s - loss: 0.0486 - accuracy: 0.9839 - val_loss: 0.3187 - val_accuracy: 0.8789\n",
      "Epoch 48/100\n",
      " - 1s - loss: 0.0760 - accuracy: 0.9693 - val_loss: 0.4699 - val_accuracy: 0.8720\n",
      "Epoch 49/100\n",
      " - 1s - loss: 0.0468 - accuracy: 0.9839 - val_loss: 0.3842 - val_accuracy: 0.8339\n",
      "Epoch 50/100\n",
      " - 1s - loss: 0.0884 - accuracy: 0.9658 - val_loss: 0.3990 - val_accuracy: 0.8720\n",
      "Epoch 51/100\n",
      " - 1s - loss: 0.0614 - accuracy: 0.9758 - val_loss: 0.4867 - val_accuracy: 0.8374\n",
      "Epoch 52/100\n",
      " - 1s - loss: 0.0539 - accuracy: 0.9823 - val_loss: 0.4213 - val_accuracy: 0.8616\n",
      "Epoch 53/100\n",
      " - 1s - loss: 0.0363 - accuracy: 0.9881 - val_loss: 0.5106 - val_accuracy: 0.8408\n",
      "Epoch 54/100\n",
      " - 1s - loss: 0.0415 - accuracy: 0.9854 - val_loss: 0.7410 - val_accuracy: 0.8166\n",
      "Epoch 55/100\n",
      " - 1s - loss: 0.2082 - accuracy: 0.9217 - val_loss: 0.4131 - val_accuracy: 0.8616\n",
      "Epoch 56/100\n",
      " - 1s - loss: 0.1257 - accuracy: 0.9536 - val_loss: 0.5013 - val_accuracy: 0.8374\n",
      "Epoch 57/100\n",
      " - 1s - loss: 0.0878 - accuracy: 0.9678 - val_loss: 0.5605 - val_accuracy: 0.8097\n",
      "Epoch 58/100\n",
      " - 1s - loss: 0.0758 - accuracy: 0.9743 - val_loss: 0.5644 - val_accuracy: 0.8235\n",
      "Epoch 59/100\n",
      " - 1s - loss: 0.0583 - accuracy: 0.9781 - val_loss: 0.6204 - val_accuracy: 0.8512\n",
      "Epoch 60/100\n",
      " - 1s - loss: 0.2970 - accuracy: 0.8983 - val_loss: 0.4006 - val_accuracy: 0.8547\n",
      "Epoch 61/100\n",
      " - 1s - loss: 0.1550 - accuracy: 0.9409 - val_loss: 0.3376 - val_accuracy: 0.8754\n",
      "Epoch 62/100\n",
      " - 1s - loss: 0.0918 - accuracy: 0.9666 - val_loss: 0.4191 - val_accuracy: 0.8374\n",
      "Epoch 63/100\n",
      " - 1s - loss: 0.1093 - accuracy: 0.9593 - val_loss: 0.4564 - val_accuracy: 0.8339\n",
      "Epoch 64/100\n",
      " - 1s - loss: 0.0881 - accuracy: 0.9662 - val_loss: 0.4085 - val_accuracy: 0.8616\n",
      "Epoch 65/100\n",
      " - 1s - loss: 0.0597 - accuracy: 0.9770 - val_loss: 0.3995 - val_accuracy: 0.8304\n",
      "Epoch 66/100\n",
      " - 1s - loss: 0.0532 - accuracy: 0.9804 - val_loss: 0.4649 - val_accuracy: 0.8374\n",
      "Epoch 67/100\n",
      " - 1s - loss: 0.0423 - accuracy: 0.9823 - val_loss: 0.4742 - val_accuracy: 0.8408\n",
      "Epoch 68/100\n",
      " - 1s - loss: 0.0437 - accuracy: 0.9823 - val_loss: 0.5613 - val_accuracy: 0.8166\n",
      "Epoch 69/100\n",
      " - 1s - loss: 0.0346 - accuracy: 0.9873 - val_loss: 0.5180 - val_accuracy: 0.8339\n",
      "Epoch 70/100\n",
      " - 1s - loss: 0.0751 - accuracy: 0.9716 - val_loss: 0.4961 - val_accuracy: 0.8166\n",
      "Epoch 71/100\n",
      " - 1s - loss: 0.0495 - accuracy: 0.9804 - val_loss: 0.4892 - val_accuracy: 0.8235\n",
      "Epoch 72/100\n",
      " - 1s - loss: 0.0354 - accuracy: 0.9881 - val_loss: 0.4731 - val_accuracy: 0.8616\n",
      "Epoch 73/100\n",
      " - 1s - loss: 0.0362 - accuracy: 0.9862 - val_loss: 0.4929 - val_accuracy: 0.8374\n",
      "Epoch 74/100\n",
      " - 1s - loss: 0.0254 - accuracy: 0.9927 - val_loss: 0.5054 - val_accuracy: 0.8374\n",
      "Epoch 75/100\n",
      " - 1s - loss: 0.0298 - accuracy: 0.9885 - val_loss: 0.4967 - val_accuracy: 0.8616\n",
      "Epoch 76/100\n",
      " - 1s - loss: 0.0245 - accuracy: 0.9912 - val_loss: 0.4439 - val_accuracy: 0.8685\n",
      "Epoch 77/100\n",
      " - 1s - loss: 0.0255 - accuracy: 0.9916 - val_loss: 0.4717 - val_accuracy: 0.8512\n",
      "Epoch 78/100\n",
      " - 1s - loss: 0.0257 - accuracy: 0.9919 - val_loss: 0.3983 - val_accuracy: 0.8512\n",
      "Epoch 79/100\n",
      " - 1s - loss: 0.0382 - accuracy: 0.9866 - val_loss: 0.4995 - val_accuracy: 0.8651\n",
      "Epoch 80/100\n",
      " - 1s - loss: 0.0357 - accuracy: 0.9854 - val_loss: 0.4549 - val_accuracy: 0.8581\n",
      "Epoch 81/100\n",
      " - 1s - loss: 0.0336 - accuracy: 0.9881 - val_loss: 0.5700 - val_accuracy: 0.8304\n",
      "Epoch 82/100\n",
      " - 1s - loss: 0.0331 - accuracy: 0.9870 - val_loss: 0.5096 - val_accuracy: 0.8443\n",
      "Epoch 83/100\n",
      " - 1s - loss: 0.0248 - accuracy: 0.9912 - val_loss: 0.4375 - val_accuracy: 0.8478\n",
      "Epoch 84/100\n",
      " - 1s - loss: 0.0228 - accuracy: 0.9916 - val_loss: 0.4881 - val_accuracy: 0.8651\n",
      "Epoch 85/100\n",
      " - 1s - loss: 0.1650 - accuracy: 0.9390 - val_loss: 0.8589 - val_accuracy: 0.7958\n",
      "Epoch 86/100\n",
      " - 1s - loss: 0.0954 - accuracy: 0.9639 - val_loss: 0.3752 - val_accuracy: 0.8685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/100\n",
      " - 1s - loss: 0.0629 - accuracy: 0.9751 - val_loss: 0.4208 - val_accuracy: 0.8720\n",
      "Epoch 88/100\n",
      " - 1s - loss: 0.0432 - accuracy: 0.9870 - val_loss: 1.5322 - val_accuracy: 0.6678\n",
      "Epoch 89/100\n",
      " - 1s - loss: 0.1060 - accuracy: 0.9612 - val_loss: 0.3859 - val_accuracy: 0.8720\n",
      "Epoch 90/100\n",
      " - 1s - loss: 0.0404 - accuracy: 0.9816 - val_loss: 0.4410 - val_accuracy: 0.8616\n",
      "Epoch 91/100\n",
      " - 1s - loss: 0.0477 - accuracy: 0.9843 - val_loss: 0.4233 - val_accuracy: 0.8754\n",
      "Epoch 92/100\n",
      " - 1s - loss: 0.0588 - accuracy: 0.9789 - val_loss: 0.4226 - val_accuracy: 0.8754\n",
      "Epoch 93/100\n",
      " - 1s - loss: 0.0383 - accuracy: 0.9873 - val_loss: 0.3878 - val_accuracy: 0.8789\n",
      "Epoch 94/100\n",
      " - 1s - loss: 0.0427 - accuracy: 0.9870 - val_loss: 0.5458 - val_accuracy: 0.8062\n",
      "Epoch 95/100\n",
      " - 1s - loss: 0.1621 - accuracy: 0.9421 - val_loss: 0.5196 - val_accuracy: 0.8270\n",
      "Epoch 96/100\n",
      " - 1s - loss: 0.0871 - accuracy: 0.9685 - val_loss: 0.5187 - val_accuracy: 0.8374\n",
      "Epoch 97/100\n",
      " - 1s - loss: 0.0710 - accuracy: 0.9724 - val_loss: 0.4576 - val_accuracy: 0.8512\n",
      "Epoch 98/100\n",
      " - 1s - loss: 0.1268 - accuracy: 0.9509 - val_loss: 0.4756 - val_accuracy: 0.8408\n",
      "Epoch 99/100\n",
      " - 1s - loss: 0.1099 - accuracy: 0.9586 - val_loss: 0.3874 - val_accuracy: 0.8651\n",
      "Epoch 100/100\n",
      " - 1s - loss: 0.0704 - accuracy: 0.9777 - val_loss: 0.4830 - val_accuracy: 0.8374\n",
      "CNN Error: 16.26%\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential, save_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import loader3\n",
    "\n",
    "batch_size = 28\n",
    "num_classes = 2\n",
    "epochs = 100\n",
    " \n",
    "train_image='E:\\\\data10\\\\classification\\\\train_resize\\\\'\n",
    "train_label= 'E:\\\\data10\\\\classification\\\\train_label.csv'\n",
    "test_image='E:\\\\data10\\\\classification\\\\test_resize\\\\'\n",
    "test_label='E:\\\\data10\\\\classification\\\\test_label.csv'\n",
    "\n",
    "\n",
    "x_train = loader3.image_load(train_image)\n",
    "y_train = loader3.label_load(train_label)\n",
    "x_test = loader3.image_load(test_image)\n",
    "y_test = loader3.label_load(test_label)      \n",
    "\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(x_train.shape[1:])\n",
    "\n",
    "#(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "# One hot Encoding\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:]))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    " \n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    " \n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    " \n",
    "hist = model.fit(x_train, y_train, validation_data=(x_test, y_test), nb_epoch=epochs, batch_size=batch_size, verbose=2)\n",
    " \n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))\n",
    " \n",
    "save_model(model, \"E:\\data10\\classification\\models\\\\result2.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf2.0-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
